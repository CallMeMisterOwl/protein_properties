{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import ExPASy\n",
    "from Bio import SwissProt\n",
    "import re\n",
    "import numpy as np\n",
    "from fasta import Fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position of glyco site is one based -> will be converted to zero based\n",
    "def fetch_protein_sequence_pdb(uniprot_id):\n",
    "    handle = ExPASy.get_sprot_raw(uniprot_id)\n",
    "    record = SwissProt.read(handle)\n",
    "    return record.sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load data\n",
    "- merge train \n",
    "- remove test from train \n",
    "- get sequences \n",
    "    - for O-linked dataset: site positions are part of the fasta header -> one header per protein is enough \n",
    "    - for the rest: group the entries by PID and accumulate glyco site positions \n",
    "- map sites to sequences\n",
    "- write to fasta file \n",
    "    - one fasta for training and one for RR, containing the PID and sequences "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/d/PycharmProjects/protein_properties/src/data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "O_captor_train = []\n",
    "with open(\"../../data/O_captor/Ptrain.fasta\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        if line.startswith(\">\"):\n",
    "            O_captor_train.append(line.strip(\"\\t\").strip(\"\\s\").strip(\"\\s\")[4:])\n",
    "rgx = re.compile('[%s]' % \"\\s\\t|\")\n",
    "O_captor_train_dict = {}\n",
    "for i in range(len(O_captor_train)):\n",
    "    O_captor_train[i] = rgx.sub(\"\", O_captor_train[i]).split(\"#\")\n",
    "    O_captor_train_dict[O_captor_train[i][0]] = set([int(j) - 1 for j in O_captor_train[i][1:]])\n",
    "O_captor_train_df = pd.Series(O_captor_train_dict.values(), O_captor_train_dict.keys())\n",
    "\n",
    "O_captor_test = []\n",
    "with open(\"../../data/O_captor/Ptrain.fasta\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        if line.startswith(\">\"):\n",
    "            O_captor_test.append(line.strip(\"\\t\").strip(\"\\s\").strip(\"\\s\")[4:])\n",
    "O_captor_test_dict = {}\n",
    "for i in range(len(O_captor_test)):\n",
    "    O_captor_test[i] = rgx.sub(\"\", O_captor_test[i]).split(\"#\")\n",
    "    O_captor_test_dict[O_captor_test[i][0]] = set([int(j) - 1 for j in O_captor_test[i][1:]])\n",
    "O_captor_test_df = pd.Series(O_captor_test_dict.values(), O_captor_test_dict.keys())\n",
    "\n",
    "N_LMNgly_train = pd.read_csv('../../data/LMNglyPred/df_train_data_without_independent_test_and_protein.csv', usecols=[\"label\",\"PID\",\"Position\"])\n",
    "N_LMNgly_test = pd.read_csv('../../data/LMNglyPred/df_independent_test_again_done_that_has_unique_protein_and_unique_sequences.csv', usecols=[\"label\",\"PID\",\"Position\"])\n",
    "N_taherzadeh_train = pd.read_csv('../../data/N_taherzadeh/Datasets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LMNgly_train_df = N_LMNgly_train.groupby(\"PID\").apply(lambda x: set([i - 1 for i in x[\"Position\"].tolist()]))\n",
    "N_LMNgly_test_df = N_LMNgly_test.groupby(\"PID\").apply(lambda x: set([i - 1 for i in x[\"Position\"].tolist()]))\n",
    "N_taherzadeh_train_df = N_taherzadeh_train.groupby(\"Protein name\").apply(lambda x: set([i - 1 for i in x[\"Position\"].tolist()]))\n",
    "N_taherzadeh_train_df.index = [str(i.replace(\"'\", \"\")) for i in N_taherzadeh_train_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q92954.3', 'P49589.3', 'Q9HBR0.2', 'O94985.1', 'Q8IYE1.2', 'P52823.1',\n",
       "       'Q6ZRP7.3', 'Q685J3.2', 'P02786.2', 'P15514.2',\n",
       "       ...\n",
       "       'Q9NVR5.2', 'O43508.1', 'P01308.1', 'Q96SB4.2', 'Q9Y561.1', 'Q8N158.1',\n",
       "       'Q03001.4', 'P31639.1', 'Q9BT09.1', 'Q9NT22.2'],\n",
       "      dtype='object', length=1326)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_captor_train_df.index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor 'union' for 'set' objects doesn't apply to a 'int' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m dubs \u001b[39m=\u001b[39m N_merged_train_df[N_merged_train_df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mduplicated()]\u001b[39m.\u001b[39mgroupby(level\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mset\u001b[39m\u001b[39m.\u001b[39munion(\u001b[39m*\u001b[39mx))\n\u001b[1;32m      3\u001b[0m N_merged_train_df \u001b[39m=\u001b[39m N_merged_train_df[N_merged_train_df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mduplicated(keep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)]\n\u001b[0;32m----> 4\u001b[0m N_merged_train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([N_merged_train_df, dubs])\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mset\u001b[39;49m\u001b[39m.\u001b[39;49munion(\u001b[39m*\u001b[39;49mx))\n",
      "File \u001b[0;32m~/PycharmProjects/protein_properties/.venv/lib/python3.10/site-packages/pandas/core/series.py:4626\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4516\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4517\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4518\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4523\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4525\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4624\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4625\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4626\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/PycharmProjects/protein_properties/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/PycharmProjects/protein_properties/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/PycharmProjects/protein_properties/.venv/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[89], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m dubs \u001b[39m=\u001b[39m N_merged_train_df[N_merged_train_df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mduplicated()]\u001b[39m.\u001b[39mgroupby(level\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mset\u001b[39m\u001b[39m.\u001b[39munion(\u001b[39m*\u001b[39mx))\n\u001b[1;32m      3\u001b[0m N_merged_train_df \u001b[39m=\u001b[39m N_merged_train_df[N_merged_train_df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mduplicated(keep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)]\n\u001b[0;32m----> 4\u001b[0m N_merged_train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([N_merged_train_df, dubs])\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mset\u001b[39;49m\u001b[39m.\u001b[39;49munion(\u001b[39m*\u001b[39;49mx))\n",
      "\u001b[0;31mTypeError\u001b[0m: descriptor 'union' for 'set' objects doesn't apply to a 'int' object"
     ]
    }
   ],
   "source": [
    "N_merged_train_df = pd.concat([N_LMNgly_train_df, N_taherzadeh_train_df])\n",
    "dubs = N_merged_train_df[N_merged_train_df.index.duplicated()].groupby(level=0).apply(lambda x: set.union(*x))\n",
    "N_merged_train_df = N_merged_train_df[N_merged_train_df.index.duplicated(keep=False)]\n",
    "N_merged_train_df = pd.concat([N_merged_train_df, dubs]).apply(lambda x: set.union(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the proteins that are in the either of the two test set\n",
    "N_merged_train_df = N_merged_train_df[~N_merged_train_df.index.isin(N_LMNgly_test_df.index)]\n",
    "N_merged_train_df = N_merged_train_df[~N_merged_train_df.index.isin(O_captor_test_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio.Seq import Seq\n",
    "import concurrent.futures\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_protein_sequences(protein_ids):\n",
    "    sequences = {}\n",
    "    \n",
    "    # Separate UniProt and NCBI IDs\n",
    "    uniprot_ids = [id for id in protein_ids if not id.startswith('NP_')]\n",
    "    ncbi_ids = [id for id in protein_ids if id.startswith('NP_')]\n",
    "    \n",
    "    # Fetch sequences for UniProt IDs\n",
    "    if uniprot_ids:\n",
    "        uniprot_sequences = fetch_uniprot_sequences(uniprot_ids)  # Fetch UniProt sequences\n",
    "        sequences.update(uniprot_sequences)\n",
    "    \n",
    "    # Fetch sequences for NCBI IDs\n",
    "    if ncbi_ids:\n",
    "        ncbi_sequences = fetch_ncbi_sequences(ncbi_ids)  # Fetch NCBI sequences\n",
    "        sequences.update(ncbi_sequences)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "def fetch_uniprot_sequences(uniprot_ids):\n",
    "    sequences = {}\n",
    "    \n",
    "    for uniprot_id in uniprot_ids:\n",
    "        \n",
    "        # Make a request to UniProt for the FASTA sequence\n",
    "        url = f'https://www.uniprot.org/uniprot/{uniprot_id}.fasta'\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.ok:\n",
    "            sequences[uniprot_id] = [''.join(response.text.split('\\n')[1:])]\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "def fetch_ncbi_sequences(ncbi_ids):\n",
    "    Entrez.email = 'your_email@example.com'  # Set your email address here\n",
    "    sequences = {}\n",
    "    \n",
    "    def fetch_sequence(ncbi_id):\n",
    "        handle = Entrez.efetch(db='protein', id=ncbi_id, rettype='fasta', retmode='text')\n",
    "        record = handle.read()\n",
    "        handle.close()\n",
    "        sequences[ncbi_id] = [record.split('\\n', 1)[1].replace('\\n', '')]\n",
    "    \n",
    "    # Fetch sequences using concurrent futures\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        executor.map(fetch_sequence, ncbi_ids)\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_PID = set((N_merged_train_df.index.tolist() + N_LMNgly_test_df.index.tolist() + O_captor_test_df.index.tolist() + O_captor_train_df.index.tolist()))\n",
    "sequences = get_protein_sequences(all_PID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fasta(sequences=sequences).write_fasta(\"../../data/glyco/glyco_all.fasta\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = Fasta(\"../../data/glyco/glyco_all.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1A5B4\n",
      "A8K7I4\n",
      "O00462\n",
      "O00533\n",
      "O00624\n",
      "O14594\n",
      "O14672\n",
      "O14917\n",
      "O15031\n",
      "O15321\n",
      "O15393\n",
      "O15455\n",
      "O15460\n",
      "O43184\n",
      "O43291\n",
      "O43451\n",
      "O43570\n",
      "O43827\n",
      "O60486\n",
      "O60602\n",
      "O75015\n",
      "O75054\n",
      "O75094\n",
      "O75197\n",
      "O75460\n",
      "O75503\n",
      "O75556\n",
      "O94813\n",
      "O94856\n",
      "O94923\n",
      "O95196\n",
      "O95274\n",
      "O95393\n",
      "O95477\n",
      "O95490\n",
      "O95970\n",
      "O95980\n",
      "O95998\n",
      "O96005\n",
      "O96014\n",
      "P00736\n",
      "P00742\n",
      "P00750\n",
      "P01133\n",
      "P01857\n",
      "P01871\n",
      "P02788\n",
      "P04216\n",
      "P05106\n",
      "P05231\n",
      "P06127\n",
      "P06729\n",
      "P06731\n",
      "P07911\n",
      "P07949\n",
      "P08069\n",
      "P08519\n",
      "P08648\n",
      "P08922\n",
      "P09326\n",
      "P09619\n",
      "P09758\n",
      "P10153\n",
      "P10586\n",
      "P11362\n",
      "P11464\n",
      "P11717\n",
      "P11912\n",
      "P12109\n",
      "P12111\n",
      "P12830\n",
      "P13284\n",
      "P13473\n",
      "P13688\n",
      "P14210\n",
      "P14679\n",
      "P14784\n",
      "P15289\n",
      "P15391\n",
      "P15813\n",
      "P16066\n",
      "P16144\n",
      "P16234\n",
      "P16278\n",
      "P16473\n",
      "P16671\n",
      "P17181\n",
      "P17927\n",
      "P18564\n",
      "P20036\n",
      "P20061\n",
      "P20138\n",
      "P20701\n",
      "P20702\n",
      "P20742\n",
      "P21439\n",
      "P21757\n",
      "P21810\n",
      "P22303\n",
      "P23229\n",
      "P23515\n",
      "P25101\n",
      "P25391\n",
      "P26006\n",
      "P26012\n",
      "P27701\n",
      "P27930\n",
      "P28827\n",
      "P29017\n",
      "P29320\n",
      "P29965\n",
      "P30530\n",
      "P31785\n",
      "P32004\n",
      "P32238\n",
      "P32942\n",
      "P33527\n",
      "P33681\n",
      "P34969\n",
      "P35052\n",
      "P35354\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'P35542'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m merged_train_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m N_merged_train_df\u001b[39m.\u001b[39mindex:\n\u001b[0;32m----> 3\u001b[0m     seq \u001b[39m=\u001b[39m sequences[i]\n\u001b[1;32m      4\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(seq))\n\u001b[1;32m      5\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/PycharmProjects/protein_properties/src/data/fasta.py:167\u001b[0m, in \u001b[0;36mFasta.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m--> 167\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sequences[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'P35542'"
     ]
    }
   ],
   "source": [
    "merged_train_dict = {}\n",
    "for i in N_merged_train_df.index:\n",
    "    seq = sequences[i]\n",
    "    labels = np.zeros(len(seq))\n",
    "    try:\n",
    "        labels[list(N_merged_train_df[i])] = 1\n",
    "    except:\n",
    "        print(i)\n",
    "    merged_train_dict[i] = [seq, labels]\n",
    "\n",
    "for i in O_captor_train_df.index:\n",
    "    seq = sequences[i]\n",
    "    if i in merged_train_dict:\n",
    "        merged_train_dict[i][list(O_captor_train_df[i])] = 2\n",
    "    else:\n",
    "        labels = np.zeros(len(seq))\n",
    "        labels[list(O_captor_train_df[i])] = 2\n",
    "        merged_train_dict[i] = [seq, labels]\n",
    "train_fasta = Fasta(sequence=merged_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
