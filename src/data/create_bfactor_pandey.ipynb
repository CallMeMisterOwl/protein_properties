{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/d/PycharmProjects/protein_properties\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from tempfile import gettempdir\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from biotite.structure.io.pdbx import PDBxFile, get_structure, get_sequence\n",
    "import biotite.structure as biostruc\n",
    "import biotite.database.rcsb as rcsb\n",
    "from biotite.sequence import ProteinSequence, AlphabetError\n",
    "from src.data.fasta import Fasta\n",
    "from os import path\n",
    "from src.utils import align_sequences_nw\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/substitution_dict.json\", \"r\") as f:\n",
    "        aa_dict = json.load(f)\n",
    "\n",
    "codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
    "# create matrix with diagonal 1\n",
    "one_hot = np.identity(len(codes))\n",
    "# create dataframe with one-hot encoding for each amino acid\n",
    "one_hot = pd.DataFrame(one_hot, index=codes, columns=codes)\n",
    "one_hot[\"AA\"] = one_hot.index\n",
    "one_hot_ss = {\"a\": [1, 0, 0], \"b\": [0, 1, 0], \"c\": [0, 0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_ala_pandey(protein: str, \n",
    "                                 pdb_path: str): \n",
    "                                 \n",
    "    cif_header: str = protein.split('-')[0]\n",
    "    try:\n",
    "        pdbx = PDBxFile.read(os.path.join(pdb_path, f'{cif_header}.cif'))\n",
    "    except FileNotFoundError:\n",
    "        print(f'Could not find PDBx file for {protein}\\nFetching from RCSB...')\n",
    "        file_path = rcsb.fetch(cif_header, \"cif\")\n",
    "        pdbx = PDBxFile.read(file_path)\n",
    "    struct = get_structure(pdbx, model=1, extra_fields=[\"b_factor\"])\n",
    "    \"\"\"seq = get_sequence(pdbx, model=1)\n",
    "    # Thank you biotite for this wonderful class, NOT!\n",
    "    try:\n",
    "        seq = ProteinSequence(list((\"\".join(protein_seq)).replace('U', 'C').replace(\"O\", \"K\")))\n",
    "    except AlphabetError:\n",
    "        print(f\"Protein {protein} contains non-canonical amino acids, skipping...\")\n",
    "        print(f\"Protein sequence: {protein_seq}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    seq_length = len(seq)\"\"\"\n",
    "    chain_id = protein.split('-')[1]\n",
    "    chain_starts = biostruc.get_chain_starts(struct).tolist()\n",
    "    chain_ids = biostruc.get_chains(struct).tolist()\n",
    "    if biostruc.get_chain_count(struct) == 1 or chain_starts[chain_ids.index(chain_id)] == chain_starts[-1]:\n",
    "        struct = struct[chain_starts[chain_ids.index(chain_id)]:]\n",
    "    else:\n",
    "        struct = struct[chain_starts[chain_ids.index(chain_id)]:chain_starts[chain_ids.index(chain_id) + 1]]\n",
    "    \n",
    "    struct = struct[biostruc.filter_amino_acids(struct)]\n",
    "    try:\n",
    "        atom_sasa_scores = biostruc.sasa(struct, vdw_radii=\"Single\", point_number=500)\n",
    "    except ValueError:\n",
    "        print(f'Skipping protein {protein}...\\n')\n",
    "        return protein, None, None\n",
    "\n",
    "    bfactor = biostruc.apply_residue_wise(struct, struct.get_annotation(\"b_factor\"), np.nanmean)\n",
    "    bfactor = (bfactor - np.nanmean(bfactor)) / np.nanstd(bfactor)\n",
    "    \n",
    "    struct_seq = []\n",
    "    for aa in biostruc.get_residues(struct)[1]:\n",
    "        try:\n",
    "            struct_seq.append(ProteinSequence.convert_letter_3to1(aa))\n",
    "        except KeyError:\n",
    "            try:\n",
    "                struct_seq.append(aa_dict[aa])\n",
    "            except KeyError:\n",
    "                struct_seq.append('X')\n",
    "    struct_ss = biostruc.annotate_sse(struct)\n",
    "    ca_list = np.array([atom.coord for atom in struct if atom.atom_name == \"CA\"])\n",
    "    try:\n",
    "        assert len(ca_list) == len(struct_seq) == len(struct_ss), f\"Length of PDB sequence ({len(seq)}) and CA atoms ({len(ca_list)}) and len SS ({len(struct_ss)}) do not match. Protein: {protein}\"\n",
    "        # TODO f this man, assert is triggered for 1 protein, need to investigate -> 115 protein affected by this -> not worth the time< \n",
    "        # I hate my life\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "        print(f\"Skipping protein {protein}...\")\n",
    "        return protein, None\n",
    "\n",
    "    ca_coord_norm = (ca_list - np.nanmean(ca_list, axis=0)) / np.nanstd(ca_list, axis=0)\n",
    "    struct_seq = [x if x in codes else \"-\" for x in struct_seq]\n",
    "    one_hot_seq = np.array(one_hot.merge(pd.DataFrame(data={\"AA\": struct_seq}), how=\"right\", on=\"AA\").drop(\"AA\", axis=1))\n",
    "    struct_ss = np.array([one_hot_ss[x] for x in struct_ss])\n",
    "\n",
    "    # !FIX: remove empty residues and adjust protein length accordingly  \n",
    "    #!----------------------------------------------------------------\n",
    "    # mask the residues that are not in the PDB files, due to disorder\n",
    "\n",
    "    assert one_hot_seq.shape[0] == len(struct_ss) == len(ca_coord_norm), f\"Length of one-hot sequence ({one_hot_seq.shape[0]}), secondary structure ({len(struct_ss)}) and CA coordinates ({len(ca_coord_norm)}) do not match\"\n",
    "    final_features = np.stack(np.concatenate([one_hot_seq, struct_ss, ca_coord_norm], axis=1))\n",
    "\n",
    "    start_end_pp = np.zeros(final_features.shape[0])\n",
    "    start_end_pp[0], start_end_pp[-1] = 1, 1\n",
    "    final_features = np.concatenate([final_features, start_end_pp[:, np.newaxis]], axis=1)    \n",
    "    prot_length = final_features.shape[0]\n",
    "    final_features = np.pad(final_features, ((0, 500 - final_features.shape[0]), (0, 0)), mode='constant', constant_values=0)\n",
    "    final_features = np.pad(final_features, ((0, 0), (0, 1)), mode='constant', constant_values=prot_length)\n",
    "\n",
    "    #!Assert no empty residues\n",
    "    \n",
    "    assert np.where(~final_features.any(axis=1))[0].shape[0] == 0\n",
    "    assert bfactor.shape[0] == len(struct_seq) == len(ca_coord_norm), f\"Length of SASA ({bfactor.shape[0]}), secondary structure ({len(struct_ss)}) and CA coordinates ({len(ca_coord_norm)}) do not match\"\n",
    "    return protein, final_features, bfactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmprwo9ifpr\n",
      "Could not find PDBx file for 4o75-A\n",
      "Fetching from RCSB...\n",
      "Done 4o75-A\n",
      "Could not find PDBx file for 1lui-A\n",
      "Fetching from RCSB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_183136/1686213900.py:38: RuntimeWarning: invalid value encountered in divide\n",
      "  bfactor = (bfactor - np.nanmean(bfactor)) / np.nanstd(bfactor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1lui-A\n",
      "Could not find PDBx file for 1jek-A\n",
      "Fetching from RCSB...\n",
      "Done 1jek-A\n",
      "Could not find PDBx file for 1jek-B\n",
      "Fetching from RCSB...\n",
      "Done 1jek-B\n",
      "Could not find PDBx file for 101m-A\n",
      "Fetching from RCSB...\n",
      "Done 101m-A\n",
      "Could not find PDBx file for 133l-A\n",
      "Fetching from RCSB...\n",
      "Done 133l-A\n"
     ]
    }
   ],
   "source": [
    "map_missing_res = Fasta(path=\"data/substitution_dict.json\")\n",
    "\n",
    "global codes\n",
    "codes = ['A', 'V', 'F', 'I', 'L','D','E','K','S','T','Y','C','N','Q', 'P','M', 'R', 'H', 'W', 'G', '-']\n",
    "# create matrix with diagonal 1\n",
    "one_hot_ss = {\"a\": [1, 0, 0], \"b\": [0, 1, 0], \"c\": [0, 0, 1]}\n",
    "global one_hot\n",
    "one_hot = np.identity(len(codes))\n",
    "# create dataframe with one-hot encoding for each amino acid\n",
    "one_hot = pd.DataFrame(one_hot, index=codes, columns=codes)\n",
    "one_hot[\"AA\"] = one_hot.index\n",
    "\n",
    "fasta_path = \"data/pandey_bfactor/seq_to_test_for.fasta\"\n",
    "# tmp path\n",
    "\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "print(temp_dir.name)\n",
    "# use temp_dir, and when done:\n",
    "\n",
    "pdb_path = temp_dir.name\n",
    "\n",
    "global aa_dict\n",
    "with open(\"data/substitution_dict.json\", \"r\") as f:\n",
    "    aa_dict = json.load(f)\n",
    "\n",
    "all_ids = []\n",
    "all_pandey_ids = []\n",
    "all_seqs = []\n",
    "with open(fasta_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\">\"):\n",
    "            pid = line[1:7].strip()\n",
    "            pandey_id = line[7:].strip()\n",
    "        else:\n",
    "            all_ids.append(pid)\n",
    "            all_pandey_ids.append(pandey_id)\n",
    "            all_seqs.append(line.strip())\n",
    "\n",
    "prots = []\n",
    "final_features = []\n",
    "bfactors = []\n",
    "# all_ids = [x for xs in all_ids for x in xs]\n",
    "for pid in all_ids:\n",
    "    prot, final_feature, bf= create_dataset_ala_pandey(pid, pdb_path)\n",
    "    if final_feature is not None:\n",
    "        prots.append(prot)\n",
    "        final_features.append(final_feature)\n",
    "        bfactors.append(bf)\n",
    "    else:\n",
    "        print(f\"Skipping {pid}\")\n",
    "        continue\n",
    "    print(f\"Done {pid}\")\n",
    "temp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = np.load(\"data/pandey_bfactor/x_61046.npy\")\n",
    "all_y = np.load(\"data/pandey_bfactor/y_61046.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        2.13764401e+00,  7.00131947e-01, -1.62279185e-02,  0.00000000e+00,\n",
       "        1.27000000e+02])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_x[int(all_pandey_ids[0])][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "       -7.08792448e-01,  2.11673951e+00,  7.59417564e-02,  0.00000000e+00,\n",
       "        1.27000000e+02])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.38153265e+00,  1.21513673e+00,  2.65594785e-01, -2.53427350e-01,\n",
       "        2.27035513e-02, -3.85778112e-02, -2.48685340e-01,  7.62335551e-01,\n",
       "        2.94821982e-01,  3.77199211e-01,  2.94958771e-01,  1.50737827e-01,\n",
       "        1.60009023e-02, -4.82300269e-01, -1.71354097e-01,  8.02966837e-02,\n",
       "        4.19419514e-04,  1.46026218e+00,  1.34499486e+00,  1.21354086e+00,\n",
       "        2.97902263e-01, -3.37324453e-01,  9.10148467e-01, -2.60722750e-01,\n",
       "       -3.55517358e-01, -2.41891498e-01,  1.49995579e+00, -3.98605816e-01,\n",
       "       -7.21427279e-01, -6.44050440e-01,  1.11101516e+00, -5.88286224e-01,\n",
       "       -1.09472379e+00, -5.46702442e-01, -4.14777286e-01, -5.43383035e-01,\n",
       "       -4.53929268e-01, -4.76368151e-01, -8.55662644e-01, -7.31276069e-01,\n",
       "       -9.73848129e-01, -8.49163106e-01, -8.23603413e-01, -7.86437402e-01,\n",
       "       -7.91463122e-01, -5.21533311e-01, -1.01713463e-02, -2.83192583e-01,\n",
       "        6.65367068e-03,  2.85277167e-01,  1.20370723e-01,  6.43496520e-01,\n",
       "       -2.13165860e-01, -1.54574676e-01, -3.48176361e-01, -8.57364905e-01,\n",
       "       -8.36937784e-01,  1.48103376e-01, -3.75944479e-01, -8.63641989e-01,\n",
       "       -1.73056357e-01, -5.14237911e-01, -6.25857535e-01, -8.87899195e-01,\n",
       "       -9.53010642e-01, -8.12574186e-01, -9.14390617e-01, -8.57486495e-01,\n",
       "       -9.72480242e-01,  1.48670796e-01,  6.44312187e-01, -7.44938364e-01,\n",
       "       -5.62022782e-01,  1.12491695e+00,  1.59271929e+00,  1.07470027e+00,\n",
       "       -3.84136605e-01, -7.45015740e-01, -6.57774911e-01, -4.32119061e-01,\n",
       "       -4.38438701e-01, -2.20294074e-01, -2.29230939e-01, -7.69698511e-01,\n",
       "       -5.17657629e-01,  2.76907722e-01, -9.63543376e-01, -8.47538221e-01,\n",
       "       -4.97549682e-01, -9.16944007e-01, -8.92367627e-01, -6.66479650e-01,\n",
       "       -4.73748439e-01, -6.69265167e-01, -8.52683689e-01, -7.13736711e-01,\n",
       "       -1.68481533e-01, -5.49043049e-01, -8.45388330e-02,  1.95124262e+00,\n",
       "        2.54034619e+00,  2.03477495e+00,  1.28088653e+00,  3.62304435e-01,\n",
       "       -3.43069581e-01, -7.74683701e-01, -2.08697427e-01, -8.47044953e-01,\n",
       "       -9.34307060e-01, -2.41430469e-01, -7.24929071e-01, -4.59568005e-01,\n",
       "       -6.27276085e-01,  2.31797830e-01, -1.54757061e-01, -5.63647667e-01,\n",
       "       -3.67965135e-01,  6.90840629e-01, -2.36607399e-01,  1.77822000e-01,\n",
       "        6.87223326e-01,  1.72581475e+00,  1.11651204e+00,  2.07489965e+00,\n",
       "        3.39281372e+00,  4.11011369e+00,  4.59735726e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfactors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y[1].squeeze()[:128].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '50', '223', '223', '33714', '51818']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pandey_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,   0.        , ...,  -0.9604993 ,\n",
       "          1.        , 130.        ],\n",
       "       [  0.        ,   1.        ,   0.        , ...,  -1.2813436 ,\n",
       "          0.        , 130.        ],\n",
       "       [  0.        ,   0.        ,   1.        , ...,  -1.24054866,\n",
       "          0.        , 130.        ],\n",
       "       ...,\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        , 130.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        , 130.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        , 130.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_x[51818]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.9999999999999997, pvalue=0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(all_x[1][:127, 26], final_features[0][:127, 26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1lun'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.load(\"data/pandey_bfactor/pdb_ids.npy\")\n",
    "ids[50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
